import numpy as np

from skfolio.optimization.online._utils import integer_simplex_grid

from ._base import CLIP_EPSILON, Loss

"""
experts: np.ndarray
    Optional expert matrix of shape ``(n_assets, n_experts)``. Each
    column is a valid portfolio on the simplex (nonnegative, sums to 1).
    If ``None``, experts are generated automatically using either a
    simplex grid (when small enough) or Dirichlet sampling (see
    ``universal_grid_step``, ``universal_n_samples``,
    ``universal_dirichlet_alpha``).

universal_grid_step: float
    If provided, attempts to discretize the simplex with grid step
    ``h`` such that the number of grid points is
    ``comb(round(1/h)+n_assets-1, n_assets-1)``. If this count exceeds
    ``universal_max_grid_points``, the implementation falls back to
    Dirichlet sampling (see below). Use small ``h`` only for small
    universes (few assets).
universal_n_samples: int
    Number of Dirichlet samples used to generate experts when a grid is
    not used. Increase to improve coverage of the simplex for larger
    universes; trades off memory/compute.
universal_dirichlet_alpha: float
    Dirichlet concentration. ``1.0`` draws are uniform over the simplex;
    values < 1 concentrate mass near the corners (extreme allocations); values > 1
    concentrate near the center (balanced allocations).
universal_max_grid_points: int
    Maximum number of grid points allowed before falling back to
    sampling when ``universal_grid_step`` is specified.
"""


class UniversalLoss(Loss):
    def __init__(self, estimator: "OPS") -> None:
        self.estimator = estimator
        self._alpha: np.ndarray | None = None
        self._experts: np.ndarray | None = None

    def _build_experts(self, n: int) -> np.ndarray:
        """Build the experts matrix. Experts are portfolios in the simplex.
        They can either be generated by a simplex grid or by sampling from a Dirichlet prior.
        """
        # 1) User-supplied experts matrix has priority
        if getattr(self.estimator, "experts", None) is not None:
            M_user = np.asarray(self.estimator.experts, dtype=float)
            if M_user.ndim != 2 or M_user.shape[0] != n:
                raise ValueError("experts matrix must have shape (n_assets, n_experts)")
            return M_user

        # 2) Grid discretization of the simplex if requested
        grid_step = self.estimator.universal_grid_step
        max_pts = self.estimator.universal_max_grid_points
        if grid_step is not None:
            if not (0.0 < float(grid_step) <= 1.0):
                raise ValueError("universal_grid_step must be in (0, 1].")
            m = round(1.0 / float(grid_step))
            n_points = math.comb(m + n - 1, n - 1)
            if n_points <= max_pts:
                grid = integer_simplex_grid(n_assets=n, m=m)
                # normalize to sum to 1 (points sum to m)
                P = grid / grid.sum(axis=1, keepdims=True)
                return P.T  # shape (n, k)
            # fall-through to sampling if grid is too large

        # 3) Dirichlet sampling as Monte Carlo / discretization
        rng = np.random.default_rng()
        n_samples = self.estimator.universal_n_samples
        alpha = self.estimator.universal_dirichlet_alpha
        if np.isscalar(alpha):
            # robust scalar conversion without relying on float() typing
            alpha_scalar = np.asarray(alpha, dtype=np.float64).item()
            alpha_vec = np.full((n,), alpha_scalar, dtype=np.float64)
        else:
            alpha_vec = np.asarray(alpha, dtype=np.float64)
            if alpha_vec.shape != (n,):
                raise ValueError(
                    "universal_dirichlet_alpha must be scalar or shape (n_assets,)"
                )
        P = rng.dirichlet(
            alpha=alpha_vec.astype(np.float64, copy=False), size=n_samples
        )
        return P.T  # shape (n, k)

    def update_weights(self, w: np.ndarray, x_gross: np.ndarray) -> np.ndarray | None:
        if self._experts is None:
            n = x_gross.shape[0]
            self._experts = self._build_experts(n)
        M = self._experts  # shape (n, k)
        # Use gross relatives provided by caller (fees modeled upstream)
        z = np.maximum(M.T @ x_gross, CLIP_EPSILON)
        losses = -np.log(z)
        # Add transaction-cost penalty per expert relative to previous weights
        tx = self.estimator._transaction_costs_arr
        prev = self.estimator.previous_weights
        if tx is not None and prev is not None:
            prev_arr = np.asarray(prev, dtype=float)
            if prev_arr.shape == (M.shape[0],):
                # cost_i = sum_j c_j * |M_{j,i} - prev_j|
                tx_arr = (
                    np.asarray(tx, dtype=float)
                    if not np.isscalar(tx)
                    else np.full(M.shape[0], tx, dtype=float)
                )
                cost_per_expert = (tx_arr[:, None] * np.abs(M - prev_arr[:, None])).sum(
                    axis=0
                )
                losses = losses + cost_per_expert
        if self._alpha is None:
            self._alpha = np.ones(M.shape[1], dtype=float) / float(M.shape[1])
        log_alpha = (
            np.log(np.maximum(self._alpha, CLIP_EPSILON)) - self.estimator.eta0 * losses
        )
        log_alpha -= np.max(log_alpha)
        alpha_raw = np.exp(log_alpha)
        s = float(alpha_raw.sum())
        self._alpha = (
            (alpha_raw / s) if s > 0 else (np.ones_like(alpha_raw) / alpha_raw.size)
        )
        w_proposed = M @ self._alpha  # convex combination of expert portfolios

        projector = self.estimator._projector
        if projector is None:
            return w_proposed
        return projector.project(w_proposed)

    def gradient(self, w: np.ndarray, x_gross: np.ndarray, **kwargs) -> np.ndarray:
        return np.zeros_like(w)

    def loss(self, w: np.ndarray, x_gross: np.ndarray, **kwargs) -> float:
        return 0.0
